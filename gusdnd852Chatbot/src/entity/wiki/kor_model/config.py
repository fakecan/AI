class config():
    embedding = "facebook"  # fasttext, word2vec, facebook
    embedding_model_path = "entity/wiki/data/w2v"
    crawler_path = "entity/wiki/data/crawler/"
    crawler_file = 'entity/wiki/source.txt'
    pos_path = "entity/wiki/data/crawler/pos.txt"
    trimmed_filename = "entity/wiki/data/processed/kor/w2v.trimmed.npz"
    charembed_filename = "entity/wiki/data/processed/kor/char.trimmed.npz"
    words_filename = "entity/wiki/data/processed/kor/words.txt"
    tags_filename = "entity/wiki/data/processed/kor/tags.txt"
    chars_filename = "entity/wiki/data/processed/kor/chars.txt"
    dev_filename = "entity/wiki/train_entity.csv"
    test_filename = "entity/wiki/train_entity.csv"
    train_filename = "entity/wiki/train_entity.csv"
    dim = 300
    dim_char = 120
    max_iter = None
    lowercase = True
    train_embeddings = False
    nepochs = 20
    dropout = 0.5
    batch_size = 10
    lr = 0.04
    lr_decay = 0.9
    nepoch_no_imprv = 300
    use_crawler = False
    hidden_size = 512
    char_hidden_size = 128
    crf = True  # size one is not allowed
    chars = True  # if char embedding, training is 3.5x slower
    output_path = "entity/wiki/results/crf/"
    model_output = output_path + "model.weights/"
    log_path = output_path + "log.txt"
