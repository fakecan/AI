Normalization과 Regularization은 과적합(Overfitting)을 방지하고 데이터를 더욱
밀집되게 하기 위해 사용된다. 즉, scale을 축소하는 과정이다.
그 이유는 scale의 범위가 과하게 커지면 유의미하지 못한 데이터 생성이나 과적합의 가능성이
생기기 때문이다. 또한 값이 너무 커지게 되면 활성화 함수 과정을 처리하더라도 한쪽으로
값이 쏠릴 가능성이 높아진다.

Normalization은 여러 개의 데이터 값을 0~1의 범위로 축소시키는 방식이다.
값의 편차가 커지면 분석하기 어려운 상황이 생기기 떄문에 0~1로 축소시켜서 분석하기 편하게
가공한다.

Regularization은 모델을 좀 더 복잡하게 하거나 유연하게 만드는 작업이다.
과적합은 모델이 훈련 데이터에 너무 딱 맞게 학습되어서 발생하는 문제인데 여기서 특정값을
가감하여 모델의 복잡도를 조정하면 훈련 데이터에 딱 맞는 상황을 일정 부분 해결할 수 있다.
주로 하이퍼 파라미터를 수정하는 방식으로 한다.


Normalization(정규화): MinMax

Standardzation(표준화): StandardScaler

Regularization(일반화, 정칙화)